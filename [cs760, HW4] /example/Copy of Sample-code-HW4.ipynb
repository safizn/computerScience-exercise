{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18oU6GKm8zFiXGBc7rHCskZQxHnsLm5X8","timestamp":1666319267297},{"file_id":"1BQX2Yr0zEgIUrfGZyD217kvIGMYWgJIB","timestamp":1666104080530},{"file_id":"1rzUh3YzB-n8gjT73TDv2mGYVBZ6pz8XU","timestamp":1666026913798}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HwjtvPdEk0YF"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","source":["Parameters\n","k= number of neurons\n","d= dimension"],"metadata":{"id":"kdA2UH9klc-s"}},{"cell_type":"code","source":["k=1\n","d=10"],"metadata":{"id":"nc6r3LZ4lJJE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialize the Random Generator"],"metadata":{"id":"VcQXzpiMhCiV"}},{"cell_type":"code","source":["g_cpu = torch.Generator()"],"metadata":{"id":"BqvmMdwUNEIf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initiazize the ground-truth vector\n","\n"],"metadata":{"id":"dc9ewd1woyjn"}},{"cell_type":"code","source":["wstar=torch.normal(0, 1, size=(k, d),generator=g_cpu )"],"metadata":{"id":"2-a0QHt7oySs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model: Relu(w.x)"],"metadata":{"id":"f9d_mw9UhOTM"}},{"cell_type":"code","source":["def model(X,w):\n","    return torch.relu(X @ w.t())"],"metadata":{"id":"cUij9UfaoLrf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mean Square-Loss"],"metadata":{"id":"BJpDP-BUhSpK"}},{"cell_type":"code","source":["def mse_loss(predictions, targets):\n","    difference = predictions - targets\n","    return torch.sum(difference * difference)/ difference.numel()"],"metadata":{"id":"c2HL9dD-spY5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculate the true label for each x"],"metadata":{"id":"t3QNOcFThUoD"}},{"cell_type":"code","source":["def calculate_optimal_label(x,wstar=wstar):\n","  return torch.sum(model(x,wstar),dim=1)"],"metadata":{"id":"vxtTc_IAo7Sw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train Parameters: N= Number of samples\n","The data are generated acording to a zero mean variance 1 gaussian."],"metadata":{"id":"aPqcQyGyhaMX"}},{"cell_type":"code","source":["N=20000\n","batch_size=500\n","train_loader= DataLoader(torch.normal(0, 1, size=(N, d),generator=g_cpu ),batch_size=batch_size,shuffle=True)"],"metadata":{"id":"zFk7JiTJsIM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w=torch.normal(0, 1, size=(k, d),generator=g_cpu ,requires_grad=True)"],"metadata":{"id":"5GRhYsbYszhA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example using autograd"],"metadata":{"id":"URq7VRZuiTR0"}},{"cell_type":"code","source":["epochs = 100\n","for i in range(epochs):\n","    stepsize=(1/np.sqrt((i+1)))/100 #step-size for this epoch\n","    for j in range(k): # WHY?\n","    # Iterate through training dataloader\n","      for x in train_loader:\n","          # Generate Prediction\n","          preds = model(x,w[j])\n","          y=calculate_optimal_label(x).detach() # WARNING: DETACH!!!! Detach-> removes the gradients generated by autograd; why?\n","          # Get the loss and perform backpropagation\n","          loss=mse_loss(preds,y)\n","          loss.backward()\n","          # Update the weights; Manual update the weights\n","          with torch.no_grad():\n","              w[j] -= w.grad[j] *stepsize\n","              # Set the gradients to zero\n","              w.grad.zero_()\n","    print(f\"Epoch {i}/{epochs}: Loss: {loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktcsJMhxmyCV","executionInfo":{"status":"ok","timestamp":1666185686421,"user_tz":300,"elapsed":6919,"user":{"displayName":"Nikos Zarifis","userId":"17641480302478882821"}},"outputId":"121e0257-336b-4dcc-b587-f2af3342a616"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/100: Loss: 6.0562968254089355\n","Epoch 1/100: Loss: 3.412588596343994\n","Epoch 2/100: Loss: 2.3759117126464844\n","Epoch 3/100: Loss: 2.2385783195495605\n","Epoch 4/100: Loss: 1.73312246799469\n","Epoch 5/100: Loss: 1.144085168838501\n","Epoch 6/100: Loss: 0.9055916666984558\n","Epoch 7/100: Loss: 0.7663824558258057\n","Epoch 8/100: Loss: 0.5273463129997253\n","Epoch 9/100: Loss: 0.4167855381965637\n","Epoch 10/100: Loss: 0.3405454754829407\n","Epoch 11/100: Loss: 0.29264017939567566\n","Epoch 12/100: Loss: 0.2609066367149353\n","Epoch 13/100: Loss: 0.205053448677063\n","Epoch 14/100: Loss: 0.1641950011253357\n","Epoch 15/100: Loss: 0.12283955514431\n","Epoch 16/100: Loss: 0.1260019987821579\n","Epoch 17/100: Loss: 0.07269932329654694\n","Epoch 18/100: Loss: 0.0728587955236435\n","Epoch 19/100: Loss: 0.05762143060564995\n","Epoch 20/100: Loss: 0.05305932089686394\n","Epoch 21/100: Loss: 0.0484728142619133\n","Epoch 22/100: Loss: 0.03445960581302643\n","Epoch 23/100: Loss: 0.03294883668422699\n","Epoch 24/100: Loss: 0.02986617386341095\n","Epoch 25/100: Loss: 0.023220794275403023\n","Epoch 26/100: Loss: 0.016453776508569717\n","Epoch 27/100: Loss: 0.019300775602459908\n","Epoch 28/100: Loss: 0.015097510069608688\n","Epoch 29/100: Loss: 0.01274497527629137\n","Epoch 30/100: Loss: 0.010799449868500233\n","Epoch 31/100: Loss: 0.009775519371032715\n","Epoch 32/100: Loss: 0.009041101671755314\n","Epoch 33/100: Loss: 0.008019032888114452\n","Epoch 34/100: Loss: 0.005921665113419294\n","Epoch 35/100: Loss: 0.006292011123150587\n","Epoch 36/100: Loss: 0.005223765503615141\n","Epoch 37/100: Loss: 0.004786372650414705\n","Epoch 38/100: Loss: 0.004204900003969669\n","Epoch 39/100: Loss: 0.0036615817807614803\n","Epoch 40/100: Loss: 0.0029104002751410007\n","Epoch 41/100: Loss: 0.002890191273763776\n","Epoch 42/100: Loss: 0.002385934814810753\n","Epoch 43/100: Loss: 0.0019977784249931574\n","Epoch 44/100: Loss: 0.0022065402008593082\n","Epoch 45/100: Loss: 0.001385725219734013\n","Epoch 46/100: Loss: 0.0012810317566618323\n","Epoch 47/100: Loss: 0.0014745803782716393\n","Epoch 48/100: Loss: 0.0012501681922003627\n","Epoch 49/100: Loss: 0.0009492539102211595\n","Epoch 50/100: Loss: 0.0009498435538262129\n","Epoch 51/100: Loss: 0.0011050221510231495\n","Epoch 52/100: Loss: 0.0007205204456113279\n","Epoch 53/100: Loss: 0.0007896781899034977\n","Epoch 54/100: Loss: 0.0006642202497459948\n","Epoch 55/100: Loss: 0.0006026026094332337\n","Epoch 56/100: Loss: 0.0005533582880161703\n","Epoch 57/100: Loss: 0.0005380326183512807\n","Epoch 58/100: Loss: 0.0004111199523322284\n","Epoch 59/100: Loss: 0.00036353271570988\n","Epoch 60/100: Loss: 0.0003122751077171415\n","Epoch 61/100: Loss: 0.0002753397566266358\n","Epoch 62/100: Loss: 0.0002737035683821887\n","Epoch 63/100: Loss: 0.00026391728897579014\n","Epoch 64/100: Loss: 0.00025698254466988146\n","Epoch 65/100: Loss: 0.00021922188170719892\n","Epoch 66/100: Loss: 0.00018827618623618037\n","Epoch 67/100: Loss: 0.00014408073911909014\n","Epoch 68/100: Loss: 0.00016736515681259334\n","Epoch 69/100: Loss: 0.00013018106983508915\n","Epoch 70/100: Loss: 0.00013844473869539797\n","Epoch 71/100: Loss: 0.00011686537618516013\n","Epoch 72/100: Loss: 9.74088761722669e-05\n","Epoch 73/100: Loss: 9.864594176178798e-05\n","Epoch 74/100: Loss: 8.367024565814063e-05\n","Epoch 75/100: Loss: 8.304527727887034e-05\n","Epoch 76/100: Loss: 7.028572144918144e-05\n","Epoch 77/100: Loss: 6.589548866031691e-05\n","Epoch 78/100: Loss: 5.84844165132381e-05\n","Epoch 79/100: Loss: 5.956647146376781e-05\n","Epoch 80/100: Loss: 6.0152200603624806e-05\n","Epoch 81/100: Loss: 4.1122308175545186e-05\n","Epoch 82/100: Loss: 5.189443254494108e-05\n","Epoch 83/100: Loss: 3.667349665192887e-05\n","Epoch 84/100: Loss: 3.4484990464989096e-05\n","Epoch 85/100: Loss: 3.0064567908993922e-05\n","Epoch 86/100: Loss: 3.1666335416957736e-05\n","Epoch 87/100: Loss: 2.725544254644774e-05\n","Epoch 88/100: Loss: 2.5381226805620827e-05\n","Epoch 89/100: Loss: 2.172635322494898e-05\n","Epoch 90/100: Loss: 2.2987089323578402e-05\n","Epoch 91/100: Loss: 1.7521642803330906e-05\n","Epoch 92/100: Loss: 1.7893302356242202e-05\n","Epoch 93/100: Loss: 1.6587071513640694e-05\n","Epoch 94/100: Loss: 1.6828054867801256e-05\n","Epoch 95/100: Loss: 1.4004118384036701e-05\n","Epoch 96/100: Loss: 1.1905430255865213e-05\n","Epoch 97/100: Loss: 1.1785461538238451e-05\n","Epoch 98/100: Loss: 1.117759893531911e-05\n","Epoch 99/100: Loss: 9.356028385809623e-06\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Wik98SbwgUPn"},"execution_count":null,"outputs":[]}]}